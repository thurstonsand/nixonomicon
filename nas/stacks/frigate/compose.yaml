services:
  frigate:
    container_name: frigate
    privileged: true
    restart: unless-stopped
    image: ghcr.io/blakeblackshear/frigate:stable
    shm_size: "675mb" # Shared memory for 6 cameras at 2K resolution
    networks:
      iot:
        ipv4_address: 192.168.3.227
    volumes:
      - /mnt/capacity/docker/frigate/config:/config
      - /mnt/capacity/docker/frigate/media/frigate:/media/frigate
      - /etc/localtime:/etc/localtime:ro
      - type: tmpfs # RAM cache for detection
        target: /tmp/cache
        tmpfs:
          size: 1000000000 # 1GB cache for detection
    ports:
      - "5000:5000" # Web UI
      - "8554:8554" # RTSP feed
      - "8555:8555" # WebRTC
      - "8555:8555/udp" # WebRTC
    environment:
      FRIGATE_RTSP_PASSWORD: "${FRIGATE_RTSP_PASSWORD}"
    # depends_on:
    #   - ollama
    devices:
      - /dev/dri:/dev/dri # Intel iGPU acceleration
    # devices:
    #   - /dev/bus/usb:/dev/bus/usb # Ready for Coral USB when added

  # ollama:
  #   container_name: ollama
  #   restart: unless-stopped
  #   image: ollama/ollama:latest
  #   networks:
  #     iot:
  #       ipv4_address: 192.168.3.228
  #   volumes:
  #     - /mnt/capacity/docker/ollama/root/.ollama:/root/.ollama
  #   ports:
  #     - "11434:11434"
  #   environment:
  #     - OLLAMA_HOST=0.0.0.0
  #     - OLLAMA_NUM_PARALLEL=1
  #     - OLLAMA_MAX_QUEUE=10
  #     - OLLAMA_MAX_LOADED_MODELS=1
  #     - OLLAMA_KEEP_ALIVE=5m
  #     - OLLAMA_CONTEXT_LENGTH=2048
  #   healthcheck:
  #     test: ["CMD-SHELL", "timeout 1 bash -c '</dev/tcp/localhost/11434' || exit 1"]
  #     interval: 10s
  #     timeout: 5s
  #     retries: 3
  #     start_period: 10s
  #   # deploy:
  #     # resources:
  #       # limits:
  #         # cpus: '8' # Limit to 8 cores for your 12600K (which has 6P+4E cores)
  #         # memory: 8G  # Limit memory usage to 8GB

  # ollama-init:
  #   container_name: ollama-init
  #   image: curlimages/curl:latest
  #   restart: on-failure
  #   networks:
  #     iot:
  #       ipv4_address: 192.168.3.229
  #   volumes:
  #     - ./ollama-init.sh:/ollama-init.sh:ro
  #   entrypoint: ["/bin/sh", "/ollama-init.sh"]
  #   depends_on:
  #     ollama:
  #       condition: service_healthy

networks:
  iot:
    external: true
